{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras_IMDb_MLP_Model 預測準確率約 80%\n",
    "# 此模型試著使用 較大的字典數 和 數字list長度 來改善預測準確率。\n",
    "# 將字典數增加到 3800，數字list長度增加到 380。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n",
      "read test files: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 執行資料前處理\n",
    "%run 'Keras_IMDb_Data_Preprocessing_Large.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding層只能作為模型的第一層，作用是將數字list轉換為向量list，\n",
    "# 讓每一個文字具有關聯性，類似語意的文字，在向量空間中會比較接近。\n",
    "# 例如，在向量空間中：\n",
    "# pleasure, like, attraction 會被分成一群，\n",
    "# hate, dislike, disgust 會被分成另一群。\n",
    "model.add(Embedding(output_dim=32, # 將數字list轉為32維度的向量\n",
    "                    input_dim=3800, # 字典改為3800字\n",
    "                    input_length=380)) # 資料長度改為380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練時，會隨機放棄 20% 神經元，以避免 overfitting。\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立完 Embedding 層後，其後可以加上 MLP、RNN、LSTM 等模型，進行深度學習。\n",
    "# 以下使用 MLP 模型作為範例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一筆資料有380個數字，每一個數字轉換為32維度的向量，\n",
    "# 因此，該平坦層有12160個神經元。\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立隱藏層\n",
    "model.add(Dense(units=256, # 隱藏層神經元數\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入 Dropout 層避免 overfitting。\n",
    "model.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立輸出層\n",
    "model.add(Dense(units=1, # 輸出層只有一個神經元\n",
    "                activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12160)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3113216   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,235,073\n",
      "Trainable params: 3,235,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模型摘要\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練方式\n",
    "model.compile(loss='binary_crossentropy', # 損失函數 \n",
    "              optimizer='adam', # 最佳化方式\n",
    "              metrics=['accuracy']) # 使用準確率評估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 0.4974 - acc: 0.7389 - val_loss: 0.4300 - val_acc: 0.8182\n",
      "Epoch 2/10\n",
      " - 15s - loss: 0.2071 - acc: 0.9200 - val_loss: 0.5522 - val_acc: 0.7652\n",
      "Epoch 3/10\n",
      " - 15s - loss: 0.0843 - acc: 0.9716 - val_loss: 0.7132 - val_acc: 0.7568\n",
      "Epoch 4/10\n",
      " - 15s - loss: 0.0308 - acc: 0.9910 - val_loss: 0.8972 - val_acc: 0.7636\n",
      "Epoch 5/10\n",
      " - 14s - loss: 0.0136 - acc: 0.9964 - val_loss: 0.9613 - val_acc: 0.7854\n",
      "Epoch 6/10\n",
      " - 15s - loss: 0.0097 - acc: 0.9975 - val_loss: 0.9233 - val_acc: 0.8016\n",
      "Epoch 7/10\n",
      " - 14s - loss: 0.0082 - acc: 0.9975 - val_loss: 1.0115 - val_acc: 0.8030\n",
      "Epoch 8/10\n",
      " - 16s - loss: 0.0143 - acc: 0.9951 - val_loss: 1.4151 - val_acc: 0.7302\n",
      "Epoch 9/10\n",
      " - 17s - loss: 0.0195 - acc: 0.9927 - val_loss: 0.8795 - val_acc: 0.8128\n",
      "Epoch 10/10\n",
      " - 15s - loss: 0.0157 - acc: 0.9946 - val_loss: 1.3909 - val_acc: 0.7558\n"
     ]
    }
   ],
   "source": [
    "# 開始訓練\n",
    "train_history = model.fit(train_feature, train_label, batch_size=100,\n",
    "                          epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 159us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83575999999999995"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評估模型準確率\n",
    "scores = model.evaluate(test_feature, test_label, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 158us/step\n"
     ]
    }
   ],
   "source": [
    "# 使用測試集進行預測\n",
    "predict = model.predict_classes(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示前 5 筆預測結果\n",
    "predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將二維陣列轉一維陣列\n",
    "predict_classes = predict.reshape(-1)\n",
    "predict_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看每篇評論預測結果\n",
    "sentiment_dic = {1:'正面的', 0:'負面的'}\n",
    "def display_sentiment(i):\n",
    "    print(test_text[i])\n",
    "    print('label值：', sentiment_dic[test_label[i]], '\\n預測結果：', sentiment_dic[predict_classes[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "label值： 正面的 \n",
      "預測結果： 正面的\n"
     ]
    }
   ],
   "source": [
    "display_sentiment(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從網路上隨便抓的一篇電影評論，作為新的預測資料\n",
    "input_text = '''\n",
    "Beauty and the Beast (2017) is a strange film to review as most of it feels like a frame by frame remake of the Disney classic.\n",
    "It's a good film by the fact that the animated version was great to begin with. Unlike The Jungle Book (2017) which improved on an average Disney film, Beauty and the Beast (2017) doesn't really warrant existing. You could have swapped the film for the original and you would have had the same amount of enjoyment.\n",
    "Any praise is really that the everyone involved did their jobs capably and produced an admirable copy. Let's hope Aladdin, Dumbo and the Lion King can bring something new and not be 'good' by being safe live action/CGI copies.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料前處理，將影評文字轉成數字陣列\n",
    "input_seq = token.texts_to_sequences([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將數字陣列裁減成固定長度380\n",
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 使用模型進行預測\n",
    "predict_result = model.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正面的'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取得預測結果\n",
    "sentiment_dic[predict_result[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 結論：增加字典數和數字list長度確實能有效增加預測準確率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
