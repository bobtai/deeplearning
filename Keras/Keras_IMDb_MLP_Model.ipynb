{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n",
      "read test files: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run 'IMDb_Data_Preprocessing.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim=2000,\n",
    "                    input_length=100))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=256,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 883,713\n",
      "Trainable params: 883,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "5s - loss: 0.4813 - acc: 0.7568 - val_loss: 0.4468 - val_acc: 0.7976\n",
      "Epoch 2/10\n",
      "4s - loss: 0.2705 - acc: 0.8896 - val_loss: 0.5277 - val_acc: 0.7656\n",
      "Epoch 3/10\n",
      "4s - loss: 0.1663 - acc: 0.9384 - val_loss: 0.6148 - val_acc: 0.7712\n",
      "Epoch 4/10\n",
      "4s - loss: 0.0878 - acc: 0.9693 - val_loss: 0.8385 - val_acc: 0.7482\n",
      "Epoch 5/10\n",
      "4s - loss: 0.0511 - acc: 0.9817 - val_loss: 1.0777 - val_acc: 0.7342\n",
      "Epoch 6/10\n",
      "4s - loss: 0.0354 - acc: 0.9884 - val_loss: 1.1269 - val_acc: 0.7524\n",
      "Epoch 7/10\n",
      "4s - loss: 0.0334 - acc: 0.9886 - val_loss: 1.2231 - val_acc: 0.7518\n",
      "Epoch 8/10\n",
      "4s - loss: 0.0282 - acc: 0.9897 - val_loss: 1.2163 - val_acc: 0.7618\n",
      "Epoch 9/10\n",
      "4s - loss: 0.0259 - acc: 0.9909 - val_loss: 1.5049 - val_acc: 0.7252\n",
      "Epoch 10/10\n",
      "4s - loss: 0.0253 - acc: 0.9903 - val_loss: 1.6365 - val_acc: 0.7166\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(train_feature, train_label, batch_size=100,\n",
    "                          epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24672/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predict = model.predict_classes(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將二維轉一維\n",
    "predict_classes = predict.reshape(-1)\n",
    "predict_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#查看每篇評論預測結果\n",
    "sentiment_dic = {1:'正面的', 0:'負面的'}\n",
    "def display_sentiment(i):\n",
    "    print(test_text[i])\n",
    "    print('label值', sentiment_dic[test_label[i]], '預測結果', sentiment_dic[predict_classes[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "label值 正面的 預測結果 正面的\n"
     ]
    }
   ],
   "source": [
    "display_sentiment(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#從網路上隨便抓的一篇電影評論，作為新資料的預測\n",
    "input_text = '''\n",
    "Beauty and the Beast (2017) is a strange film to review as most of it feels like a frame by frame remake of the Disney classic.\n",
    "It's a good film by the fact that the animated version was great to begin with. Unlike The Jungle Book (2017) which improved on an average Disney film, Beauty and the Beast (2017) doesn't really warrant existing. You could have swapped the film for the original and you would have had the same amount of enjoyment.\n",
    "Any praise is really that the everyone involved did their jobs capably and produced an admirable copy. Let's hope Aladdin, Dumbo and the Lion King can bring something new and not be 'good' by being safe live action/CGI copies.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#資料預處理，將影評文字轉成數字陣列\n",
    "input_seq = token.texts_to_sequences([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#將數字陣列裁減成固定長度100\n",
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "#使用模型進行預測\n",
    "predict_result = model.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正面的'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取得預測結果\n",
    "sentiment_dic[predict_result[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
