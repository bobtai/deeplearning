{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, offset, length):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12, 14)\n",
    "    if length > 10: length = 10\n",
    "    for i in range(0, length):\n",
    "        ax = plt.subplot(2, 5, 1+i)\n",
    "        ax.imshow(images[offset], cmap='binary')\n",
    "        \n",
    "        ax.set_xticks([]);\n",
    "        ax.set_yticks([]);\n",
    "        offset += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read all images in list.\n",
    "handwrite0 = '/Users/PChomeIM/uploads/0.png'\n",
    "handwrite1 = '/Users/PChomeIM/uploads/1.png'\n",
    "handwrite3 = '/Users/PChomeIM/uploads/3.png'\n",
    "handwrite_images = [handwrite0, handwrite1, handwrite3]\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/train/string_input_producer\n",
    "# Make a queue of file names including all the images \n",
    "# default shuffle = True, If true, the strings are randomly shuffled within each epoch.\n",
    "filename_queue = tf.train.string_input_producer(handwrite_images, shuffle=False)\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/WholeFileReader\n",
    "# To use, enqueue filenames in a Queue. \n",
    "# The output of Read will be a filename (key) and the contents of that file (value).\n",
    "reader = tf.WholeFileReader()\n",
    "# reader.read: Returns the next record (key, value pair) produced by a reader.\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# https://www.tensorflow.org/versions/r0.12/api_docs/python/image/encoding_and_decoding\n",
    "# The encode and decode Ops apply to one image at a time.\n",
    "# If you need fixed size images, pass the output of the decode Ops to one of the cropping and resizing Ops.\n",
    "# channels=1: output a grayscale image.\n",
    "# channels=3: output an RGB image.\n",
    "myimg = tf.image.decode_png(value, channels=1)\n",
    "crop_myimg = tf.image.resize_image_with_crop_or_pad(myimg, 135, 135) #置中裁減\n",
    "resize_myimg = tf.image.resize_images(crop_myimg, [28, 28]) #調整大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# The TensorFlow Session object is multithreaded and thread-safe, \n",
    "# so multiple threads can easily use the same session and run ops in parallel.\n",
    "with tf.Session() as sess:\n",
    "    # Return an Op that initializes global variables in the graph.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # http://www.jianshu.com/p/d063804fb272\n",
    "    # https://www.tensorflow.org/programmers_guide/threading_and_queues\n",
    "    # The Coordinator class helps multiple threads stop together and report exceptions to a program that waits for them to stop. \n",
    "    # The QueueRunner class is used to create a number of threads cooperating to enqueue tensors in the same queue.\n",
    "    # These two classes are designed to be used together. \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    # Collect all images tensor\n",
    "    all_images = []\n",
    "    \n",
    "    # Main thread, consumes all job.\n",
    "    for i in range(len(handwrite_images)):\n",
    "        '''\n",
    "        The difference is in Operations and Tensors. \n",
    "        Operations use run() and Tensors use eval().\n",
    "        In this example, resize_myimg is a tensor.\n",
    "        And tensor.eval() is equivalent to sess.run(tensor).\n",
    "        ''' \n",
    "        image = resize_myimg.eval() # is equivalent to sess.run(resize_myimg)\n",
    "        reshape_image = image.reshape(image.shape[0], image.shape[1])\n",
    "        abs_image = abs(255-reshape_image)\n",
    "        all_images.append(abs_image)\n",
    "        #print(abs_image.shape)\n",
    "        #print(abs_image)\n",
    "        \n",
    "    # Convert list to numpy array format\n",
    "    all_images = np.array(all_images, dtype=np.int16)\n",
    "    print(all_images.shape)\n",
    "    \n",
    "    # Save train data to binary format\n",
    "    all_images.tofile('train.dat')\n",
    "\n",
    "    # When done, ask the threads to stop.\n",
    "    coord.request_stop()\n",
    "    # And wait for threads actually stop.\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAACICAYAAAA8szY+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP4wgMmkoE2XUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1250fe5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(all_images, 0, all_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
